{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "2.실행 가능성 확인하기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzickso/smart_factory/blob/main/2_%EC%8B%A4%ED%96%89_%EA%B0%80%EB%8A%A5%EC%84%B1_%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBTTgHxd6DC"
      },
      "source": [
        "# 실행 가능성 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5LWaQiud_aE",
        "outputId": "27308c30-f382-40bf-cce0-49a8180d0c54"
      },
      "source": [
        "pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 29kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.36.2)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.0.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, h5py, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BqU3Xvzd6DG"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAhdXyfzeGwP",
        "outputId": "3a2c56d3-b6c8-414e-d21d-23132ec72785"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J90nnadceSO3",
        "outputId": "11e5ffba-ebbb-4246-d043-895741d4892b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW0IWy4_PaMJ"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/busan_smart')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86k20mmsd6DI"
      },
      "source": [
        "## 하이퍼파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKTfq1k5d6DI"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "DATASET_PATH = 'dataset/2/'\n",
        "DATASET_OK_PATTERN = DATASET_PATH + 'OK/*.png'\n",
        "DATASET_FAIL_PATTERN = DATASET_PATH + 'FAIL/*.png'\n",
        "\n",
        "RESULT_SAVE_PATH = 'results/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4MREV29d6DJ"
      },
      "source": [
        "## 단순한 모델 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqmAb6BMd6DJ"
      },
      "source": [
        "def Model():\n",
        "    return Sequential([Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)), #tensorflow 버전업으로 코드 변경\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(64, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(128, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(256, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Flatten(),\n",
        "                       Dense(1, activation='sigmoid')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5Fte1Wqd6DK"
      },
      "source": [
        "## 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ked-oqjcd6DK"
      },
      "source": [
        "def preprocess(file_name):\n",
        "    img = tf.io.read_file(file_name)\n",
        "    img = tf.image.decode_png(img, channels=1) #tensorflow 버전업으로 코드 변경\n",
        "    return tf.image.convert_image_dtype(img, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnwVUYo4d6DK"
      },
      "source": [
        "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
        "ds_ok = tf.data.Dataset.list_files(ok_list)\n",
        "ds_ok_label = tf.data.Dataset.from_tensor_slices([0] * len(ok_list))\n",
        "\n",
        "ds_ok = ds_ok.map(preprocess)\n",
        "ds_ok = tf.data.Dataset.zip((ds_ok, ds_ok_label))\n",
        "\n",
        "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
        "ds_fail = tf.data.Dataset.list_files(fail_list)\n",
        "ds_fail_label = tf.data.Dataset.from_tensor_slices([1] * len(fail_list))\n",
        "\n",
        "ds_fail = ds_fail.map(preprocess)\n",
        "ds_fail = tf.data.Dataset.zip((ds_fail, ds_fail_label))\n",
        "\n",
        "ds = tf.data.Dataset.concatenate(ds_ok, ds_fail)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqH4BLM0d6DL"
      },
      "source": [
        "## Train, Valid 데이터셋 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00DeMFYpd6DL"
      },
      "source": [
        "ds_size = len(ok_list) + len(fail_list)\n",
        "train_size = int(ds_size * 0.7)\n",
        "\n",
        "ds = ds.shuffle(ds_size)\n",
        "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).batch(32)\n",
        "ds_valid = ds.skip(train_size).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2un3AKAd6DL"
      },
      "source": [
        "## 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Q9oh7OEHd6DM"
      },
      "source": [
        "model = Model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3en1OOcd6DM",
        "outputId": "00599cf7-e82d-4e72-824d-06bfd733ace9"
      },
      "source": [
        "model.fit(ds_train, validation_data=ds_valid, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "31/31 [==============================] - 6s 180ms/step - loss: 0.3433 - accuracy: 0.9123 - val_loss: 0.3009 - val_accuracy: 0.9145\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 5s 167ms/step - loss: 0.3163 - accuracy: 0.9072 - val_loss: 0.3221 - val_accuracy: 0.9002\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 5s 165ms/step - loss: 0.2997 - accuracy: 0.9113 - val_loss: 0.2741 - val_accuracy: 0.9240\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 5s 169ms/step - loss: 0.2830 - accuracy: 0.9123 - val_loss: 0.2666 - val_accuracy: 0.9264\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 5s 164ms/step - loss: 0.3099 - accuracy: 0.9083 - val_loss: 0.2777 - val_accuracy: 0.9169\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 5s 164ms/step - loss: 0.2922 - accuracy: 0.9062 - val_loss: 0.2731 - val_accuracy: 0.9192\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 5s 166ms/step - loss: 0.2900 - accuracy: 0.9134 - val_loss: 0.2395 - val_accuracy: 0.9169\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 5s 163ms/step - loss: 0.2792 - accuracy: 0.9154 - val_loss: 0.3082 - val_accuracy: 0.8979\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 5s 165ms/step - loss: 0.2805 - accuracy: 0.9134 - val_loss: 0.2372 - val_accuracy: 0.9359\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 5s 165ms/step - loss: 0.2705 - accuracy: 0.9134 - val_loss: 0.2690 - val_accuracy: 0.9287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0aa074dd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZreSz-GMd6DO"
      },
      "source": [
        "## 결과를 이미지로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Q7TNm2xnd6DO"
      },
      "source": [
        "def mkdir(path):\n",
        "    if os.path.exists(path) is False:\n",
        "        os.mkdir(path)\n",
        "\n",
        "mkdir(RESULT_SAVE_PATH)\n",
        "mkdir(RESULT_SAVE_PATH + '/TP')\n",
        "mkdir(RESULT_SAVE_PATH + '/TN')\n",
        "mkdir(RESULT_SAVE_PATH + '/FP')\n",
        "mkdir(RESULT_SAVE_PATH + '/FN')\n",
        "\n",
        "index = 0\n",
        "for imgs, labels in ds_valid:\n",
        "    preds = model.predict(imgs)\n",
        "    for idx in range(imgs.shape[0]):\n",
        "        gt = labels[idx].numpy()\n",
        "        y = preds[idx]\n",
        "        \n",
        "        if gt == 1 and y > 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/TP'\n",
        "        elif gt == 1 and y <= 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/FN'\n",
        "        elif gt == 0 and y > 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/FP'\n",
        "        else:\n",
        "            path = RESULT_SAVE_PATH + '/TN'\n",
        "            \n",
        "        cv2.imwrite(path + '/%.4f_%04d.png' % (y, index), imgs[idx].numpy() * 255)\n",
        "        index +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nkIUWvPd6DO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}