{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "실습 환경 준비.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzickso/smart_factory/blob/main/%EC%8B%A4%EC%8A%B5_%ED%99%98%EA%B2%BD_%EC%A4%80%EB%B9%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKMNv2YOLfte"
      },
      "source": [
        "# 실습 환경 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJaxL5pTLheL",
        "outputId": "ec479530-e9f6-4f20-d7dc-953499afbc26"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yfL8bbZAzJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ea5d6f-2d7c-45ca-a944-fa31f8b98b0c"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/smart_factory')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " dataset  '실습 환경 준비.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95cJvAHmLftf",
        "outputId": "e01d1dff-71b8-4019-980f-05f88d67427c"
      },
      "source": [
        "import sys\n",
        "print (sys.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib-GjROMLftg",
        "outputId": "03cb5e31-8b00-47e8-b8f5-4d1652200179"
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ND8_ifbTlZX",
        "outputId": "a60322dc-e3f7-48fc-bf18-4213034bc6ee"
      },
      "source": [
        "pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.36.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.34.1)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 34.3MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 25.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.31.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2021.5.30)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.5.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.1)\n",
            "Installing collected packages: h5py, tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4guABlgsUPRo",
        "outputId": "7a34c124-569c-486e-f300-fd4d68f7314e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwnprzvTLftg"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F77uu0huLfth"
      },
      "source": [
        "PATH_DEFECT = 'dataset/Defect_images/'\n",
        "PATH_MASK = 'dataset/Mask_images/'\n",
        "PATH_NODEFECT = 'dataset/NODefect_images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UTMSOrMfLfth",
        "outputId": "9da5ab4b-5191-4a29-da8a-f8fcf687f68f"
      },
      "source": [
        "defect_list = glob.glob(PATH_DEFECT + '*.png')\n",
        "defect_list[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dataset/Defect_images/0075_010_03.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Joc34RIoLfti"
      },
      "source": [
        "## Dataset 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7u0nKQILfti"
      },
      "source": [
        "random.seed(0)\n",
        "\n",
        "defect_list = glob.glob(PATH_DEFECT + '*.png')\n",
        "mask_list = glob.glob(PATH_MASK + '*.png')\n",
        "pass_list = glob.glob(PATH_NODEFECT + '**/*.png')\n",
        "\n",
        "# Match defect-mask pairs\n",
        "new_defect_list = list()\n",
        "new_mask_list = list()\n",
        "for defect in defect_list:\n",
        "    num = defect.split('/')[-1].split('_')[0]\n",
        "    for mask in mask_list:\n",
        "        num_mask = mask.split('/')[-1].split('_')[0]\n",
        "        if num == num_mask:\n",
        "            new_defect_list.append(defect)\n",
        "            new_mask_list.append(mask)\n",
        "            break\n",
        "defect_list = new_defect_list\n",
        "mask_list = new_mask_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtOw96sOLftj",
        "outputId": "93713448-0adc-4bdf-bbd5-6e2597b4f987"
      },
      "source": [
        "new_mask_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dataset/Mask_images/0075_010_03_mask.png',\n",
              " 'dataset/Mask_images/0076_030_03_mask.png',\n",
              " 'dataset/Mask_images/0095_010_03_mask.png',\n",
              " 'dataset/Mask_images/0096_030_03_mask.png',\n",
              " 'dataset/Mask_images/0101_022_03_mask.png',\n",
              " 'dataset/Mask_images/0102_010_03_mask.png',\n",
              " 'dataset/Mask_images/0103_010_03_mask.png',\n",
              " 'dataset/Mask_images/0104_022_03_mask.png',\n",
              " 'dataset/Mask_images/0105_010_03_mask.png',\n",
              " 'dataset/Mask_images/0106_010_03_mask.png',\n",
              " 'dataset/Mask_images/0107_025_03_mask.png',\n",
              " 'dataset/Mask_images/0108_025_03_mask.png',\n",
              " 'dataset/Mask_images/0109_025_03_mask.png',\n",
              " 'dataset/Mask_images/0077_022_03_mask.png',\n",
              " 'dataset/Mask_images/0074_010_03_mask.png',\n",
              " 'dataset/Mask_images/0079_025_03_mask.png',\n",
              " 'dataset/Mask_images/0078_025_03_mask.png',\n",
              " 'dataset/Mask_images/0073_010_03_mask.png',\n",
              " 'dataset/Mask_images/0072_010_03_mask.png',\n",
              " 'dataset/Mask_images/0098_019_02_mask.png',\n",
              " 'dataset/Mask_images/0099_019_02_mask.png',\n",
              " 'dataset/Mask_images/0001_002_00_mask.png',\n",
              " 'dataset/Mask_images/0002_002_00_mask.png',\n",
              " 'dataset/Mask_images/0003_002_00_mask.png',\n",
              " 'dataset/Mask_images/0004_002_01_mask.png',\n",
              " 'dataset/Mask_images/0005_002_01_mask.png',\n",
              " 'dataset/Mask_images/0006_002_01_mask.png',\n",
              " 'dataset/Mask_images/0010_006_02_mask.png',\n",
              " 'dataset/Mask_images/0011_006_02_mask.png',\n",
              " 'dataset/Mask_images/0012_006_02_mask.png',\n",
              " 'dataset/Mask_images/0013_006_02_mask.png',\n",
              " 'dataset/Mask_images/0014_006_02_mask.png',\n",
              " 'dataset/Mask_images/0015_006_02_mask.png',\n",
              " 'dataset/Mask_images/0016_006_02_mask.png',\n",
              " 'dataset/Mask_images/0017_002_02_mask.png',\n",
              " 'dataset/Mask_images/0018_010_03_mask.png',\n",
              " 'dataset/Mask_images/0019_016_03_mask.png',\n",
              " 'dataset/Mask_images/0020_016_03_mask.png',\n",
              " 'dataset/Mask_images/0021_016_03_mask.png',\n",
              " 'dataset/Mask_images/0022_019_02_mask.png',\n",
              " 'dataset/Mask_images/0023_019_02_mask.png',\n",
              " 'dataset/Mask_images/0024_019_02_mask.png',\n",
              " 'dataset/Mask_images/0025_019_02_mask.png',\n",
              " 'dataset/Mask_images/0026_019_02_mask.png',\n",
              " 'dataset/Mask_images/0027_019_02_mask.png',\n",
              " 'dataset/Mask_images/0028_019_02_mask.png',\n",
              " 'dataset/Mask_images/0029_019_02_mask.png',\n",
              " 'dataset/Mask_images/0030_019_02_mask.png',\n",
              " 'dataset/Mask_images/0031_019_02_mask.png',\n",
              " 'dataset/Mask_images/0032_019_02_mask.png',\n",
              " 'dataset/Mask_images/0033_019_02_mask.png',\n",
              " 'dataset/Mask_images/0034_019_02_mask.png',\n",
              " 'dataset/Mask_images/0035_019_02_mask.png',\n",
              " 'dataset/Mask_images/0036_019_02_mask.png',\n",
              " 'dataset/Mask_images/0037_019_02_mask.png',\n",
              " 'dataset/Mask_images/0038_019_02_mask.png',\n",
              " 'dataset/Mask_images/0039_019_02_mask.png',\n",
              " 'dataset/Mask_images/0040_019_02_mask.png',\n",
              " 'dataset/Mask_images/0041_019_02_mask.png',\n",
              " 'dataset/Mask_images/0042_019_02_mask.png',\n",
              " 'dataset/Mask_images/0043_019_04_mask.png',\n",
              " 'dataset/Mask_images/0044_019_04_mask1.png',\n",
              " 'dataset/Mask_images/0045_019_04_mask.png',\n",
              " 'dataset/Mask_images/0046_019_04_mask.png',\n",
              " 'dataset/Mask_images/0047_019_04_mask.png',\n",
              " 'dataset/Mask_images/0048_019_04_mask.png',\n",
              " 'dataset/Mask_images/0050_019_03_mask.png',\n",
              " 'dataset/Mask_images/0051_019_03_mask.png',\n",
              " 'dataset/Mask_images/0052_019_03_mask.png',\n",
              " 'dataset/Mask_images/0053_019_03_mask.png',\n",
              " 'dataset/Mask_images/0054_019_03_mask.png',\n",
              " 'dataset/Mask_images/0055_019_06_mask.png',\n",
              " 'dataset/Mask_images/0056_019_06_mask.png',\n",
              " 'dataset/Mask_images/0057_019_06_mask.png',\n",
              " 'dataset/Mask_images/0058_019_06_mask.png',\n",
              " 'dataset/Mask_images/0059_019_01_mask.png',\n",
              " 'dataset/Mask_images/0060_022_06_mask.png',\n",
              " 'dataset/Mask_images/0061_022_06_mask.png',\n",
              " 'dataset/Mask_images/0062_022_00_mask.png',\n",
              " 'dataset/Mask_images/0063_022_00_mask.png',\n",
              " 'dataset/Mask_images/0064_022_00_mask.png',\n",
              " 'dataset/Mask_images/0065_022_00_mask.png',\n",
              " 'dataset/Mask_images/0066_023_01_mask.png',\n",
              " 'dataset/Mask_images/0067_023_01_mask.png',\n",
              " 'dataset/Mask_images/0068_023_02_mask.png',\n",
              " 'dataset/Mask_images/0069_023_02_mask.png',\n",
              " 'dataset/Mask_images/0070_023_02_mask.png',\n",
              " 'dataset/Mask_images/0080_036_01_mask.png',\n",
              " 'dataset/Mask_images/0085_030_02_mask.png',\n",
              " 'dataset/Mask_images/0086_030_02_mask.png',\n",
              " 'dataset/Mask_images/0087_030_02_mask.png',\n",
              " 'dataset/Mask_images/0088_030_02_mask.png',\n",
              " 'dataset/Mask_images/0089_002_01_mask.png',\n",
              " 'dataset/Mask_images/0090_002_01_mask.png',\n",
              " 'dataset/Mask_images/0091_030_01_mask.png',\n",
              " 'dataset/Mask_images/0092_030_01_mask.png',\n",
              " 'dataset/Mask_images/0093_030_01_mask.png',\n",
              " 'dataset/Mask_images/0094_027_05_mask.png',\n",
              " 'dataset/Mask_images/0081_006_04_mask.png',\n",
              " 'dataset/Mask_images/0082_030_04_mask.png',\n",
              " 'dataset/Mask_images/0083_029_04_mask.png',\n",
              " 'dataset/Mask_images/0084_030_04_mask.png',\n",
              " 'dataset/Mask_images/0071_030_03_mask.png',\n",
              " 'dataset/Mask_images/0049_030_03_mask.png',\n",
              " 'dataset/Mask_images/0097_030_03_mask1.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX_ANcWgLftj"
      },
      "source": [
        "## 첫 발송 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id5ItER3Lftj"
      },
      "source": [
        "# The first dataset given\n",
        "if os.path.exists('dataset/1') is False:\n",
        "    os.mkdir('dataset/1')\n",
        "for file_name in pass_list + defect_list:\n",
        "    if random.randint(0, 9) < 2:\n",
        "        barcode = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
        "        shutil.copy2(file_name, 'dataset/1/' + barcode + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGHqxLNTLftk"
      },
      "source": [
        "## 두번째 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiEqrH3zLftk"
      },
      "source": [
        "# The second dataset\n",
        "if os.path.exists('dataset/2') is False:\n",
        "    os.mkdir('dataset/2')\n",
        "if os.path.exists('dataset/2/OK') is False:\n",
        "    os.mkdir('dataset/2/OK')\n",
        "if os.path.exists('dataset/2/FAIL') is False:\n",
        "    os.mkdir('dataset/2/FAIL')\n",
        "idx = 0\n",
        "\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 3:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('dataset/2/OK/%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_list.append(patch)\n",
        "\n",
        "random.shuffle(patch_list)\n",
        "patch_list_fraction = patch_list[:len(patch_list)//3]\n",
        "for idx, patch in enumerate(patch_list_fraction):\n",
        "    cv2.imwrite('dataset/2/FAIL/%04d.png' % idx, patch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pEuQdF9Lftl"
      },
      "source": [
        "## 세번째 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtaH1BReLftl"
      },
      "source": [
        "# The third dataset\n",
        "if os.path.exists('dataset/3') is False:\n",
        "    os.mkdir('dataset/3')\n",
        "if os.path.exists('dataset/3/OK') is False:\n",
        "    os.mkdir('dataset/3/OK')\n",
        "if os.path.exists('dataset/3/FAIL') is False:\n",
        "    os.mkdir('dataset/3/FAIL')\n",
        "if os.path.exists('dataset/3/MASK') is False:\n",
        "    os.mkdir('dataset/3/MASK')\n",
        "idx = 0\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 3:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('dataset/3/OK/%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_pair_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_pair_list.append((patch, patch_d))\n",
        "\n",
        "random.shuffle(patch_pair_list)\n",
        "for idx, pair in enumerate(patch_pair_list):\n",
        "    patch, patch_d = pair\n",
        "    cv2.imwrite('dataset/3/FAIL/%04d.png' % idx, patch)\n",
        "    cv2.imwrite('dataset/3/MASK/%04d.png' % idx, patch_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnmSXP_xLftl"
      },
      "source": [
        "## 실전 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OLrESyCLftm"
      },
      "source": [
        "# The test dataset\n",
        "if os.path.exists('data/') is False:\n",
        "    os.mkdir('data/')\n",
        "if os.path.exists('tfrecords/') is False:\n",
        "    os.mkdir('tfrecords/')\n",
        "if os.path.exists('model/') is False:\n",
        "    os.mkdir('model/')\n",
        "if os.path.exists('data/input_data') is False:\n",
        "    os.mkdir('data/input_data')\n",
        "if os.path.exists('data/output_csv') is False:\n",
        "    os.mkdir('data/output_csv')\n",
        "    \n",
        "idx = 0\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 5:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('data/input_data/ok_%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_pair_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_pair_list.append((patch, patch_d))\n",
        "\n",
        "random.shuffle(patch_pair_list)\n",
        "for idx, pair in enumerate(patch_pair_list):\n",
        "    patch, patch_d = pair\n",
        "    cv2.imwrite('data/input_data/fail_%04d.png' % idx, patch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyC2YGvdLftn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}